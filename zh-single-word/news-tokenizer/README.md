# news-tokenizer

## 作用：对中文数据集 news2016zh_train.json 按照单个字分词，并且生成词频（词表）文件

声明一下news2016数据集 从这个[github链接](https://github.com/brightmart/nlp_chinese_corpus)找到的


也可以从这里直接进入[文件直链](https://pan.baidu.com/s/1MLLM-CdM6BhJkj8D0u3atA?errno=0&errmsg=Auth%20Login%20Sucess&&bduss=&ssnerror=0&traceid=) 密码:k265

|-main.py  读取news2016zh_train.json按照单个字，生成train，test，dev分词后的文件 和 词频文件
|
|-news_config.py  包含 样本数量 和 文件名
|

